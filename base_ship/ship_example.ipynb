{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90ca7e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in ./anaconda3/lib/python3.10/site-packages (2.13.0rc1)\n",
      "Requirement already satisfied: numpy in ./anaconda3/lib/python3.10/site-packages (1.23.5)\n",
      "Requirement already satisfied: matplotlib in ./anaconda3/lib/python3.10/site-packages (3.7.0)\n",
      "Requirement already satisfied: opencv-python in ./anaconda3/lib/python3.10/site-packages (4.7.0.72)\n",
      "Requirement already satisfied: scikit-learn in ./anaconda3/lib/python3.10/site-packages (1.2.1)\n",
      "Requirement already satisfied: tensorflow-macos==2.13.0-rc1 in ./anaconda3/lib/python3.10/site-packages (from tensorflow) (2.13.0rc1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: packaging in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.54.2)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (4.23.2)\n",
      "Requirement already satisfied: six>=1.12.0 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1rc0 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.13.1rc0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0rc0 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.13.0rc0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./anaconda3/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./anaconda3/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./anaconda3/lib/python3.10/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./anaconda3/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./anaconda3/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./anaconda3/lib/python3.10/site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./anaconda3/lib/python3.10/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./anaconda3/lib/python3.10/site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in ./anaconda3/lib/python3.10/site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./anaconda3/lib/python3.10/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./anaconda3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0-rc1->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.20.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: urllib3<2.0 in ./anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./anaconda3/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./anaconda3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./anaconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./anaconda3/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow numpy matplotlib opencv-python scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f0f2d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c6b3478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory path where your data is stored\n",
    "data_dir = '/Users/ihortresnystkyi/train_v2'\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(os.path.join(data_dir, 'train_ship_segmentations_v2.csv'))\n",
    "\n",
    "# Initialize lists to store the images and masks\n",
    "images = []\n",
    "masks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "859e34ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert RLE to mask\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0377e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 images\n",
      "Processed 1000 images\n",
      "Processed 2000 images\n",
      "Processed 3000 images\n",
      "Processed 4000 images\n",
      "Processed 5000 images\n",
      "Processed 6000 images\n",
      "Processed 7000 images\n",
      "Processed 8000 images\n",
      "Processed 9000 images\n",
      "Processed 10000 images\n",
      "Processed 11000 images\n",
      "Processed 12000 images\n",
      "Processed 13000 images\n",
      "Processed 14000 images\n",
      "Processed 15000 images\n",
      "Processed 16000 images\n",
      "Processed 17000 images\n",
      "Processed 18000 images\n",
      "Processed 19000 images\n",
      "Processed 20000 images\n",
      "Processed 21000 images\n",
      "Processed 22000 images\n",
      "Processed 23000 images\n",
      "Processed 24000 images\n",
      "Processed 25000 images\n",
      "Processed 26000 images\n",
      "Processed 27000 images\n",
      "Processed 28000 images\n",
      "Processed 29000 images\n",
      "Processed 30000 images\n",
      "Processed 31000 images\n",
      "Processed 32000 images\n",
      "Processed 33000 images\n",
      "Processed 34000 images\n",
      "Processed 35000 images\n",
      "Processed 36000 images\n",
      "Processed 37000 images\n",
      "Processed 38000 images\n",
      "Processed 39000 images\n",
      "Processed 40000 images\n",
      "Processed 41000 images\n",
      "Processed 42000 images\n",
      "Processed 43000 images\n",
      "Processed 44000 images\n",
      "Processed 45000 images\n",
      "Processed 46000 images\n",
      "Processed 47000 images\n",
      "Processed 48000 images\n",
      "Processed 49000 images\n",
      "Processed 50000 images\n",
      "Processed 51000 images\n",
      "Processed 52000 images\n",
      "Processed 53000 images\n"
     ]
    }
   ],
   "source": [
    "# Loop over the rows of the DataFrame\n",
    "for idx, row in df.iterrows():\n",
    "    # Get the image ID and the RLE mask\n",
    "    image_id = row['ImageId']\n",
    "    rle_mask = row['EncodedPixels']\n",
    "\n",
    "    if isinstance(rle_mask, str): # Only process images that have ship\n",
    "        # Decode the RLE mask\n",
    "        mask = rle_decode(rle_mask)\n",
    "\n",
    "        # Open the image file\n",
    "        image = Image.open(os.path.join(data_dir, f'{image_id}'))\n",
    "\n",
    "        # Append the image and mask to the lists\n",
    "        images.append(np.array(image))\n",
    "        masks.append(mask)\n",
    "\n",
    "    # Print a progress message every 1000 images\n",
    "    if idx % 1000 == 0:\n",
    "        print(f\"Processed {idx} images\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "print(\"Converting lists to arrays\")\n",
    "X = np.array(images)\n",
    "Y = np.array(masks)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "833748a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into train and validation sets\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSplitting data into train and validation sets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mX\u001b[49m, Y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Splitting data into train and validation sets\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca7e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_size=(768, 768, 1)):\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    # Downsampling path\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    # Upsampling path\n",
    "    up1 = UpSampling2D(size=(2, 2))(pool1)\n",
    "    merge1 = concatenate([conv1, up1], axis=3)\n",
    "    conv2 = Conv2D(1, (1, 1), activation='sigmoid')(merge1)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=conv2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142fa702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom metric (Dice coefficient)\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = tf.reduce_sum(y_true, axis=[1,2,3]) + tf.reduce_sum(y_pred, axis=[1,2,3])\n",
    "    return tf.reduce_mean((2. * intersection + smooth) / (union + smooth))\n",
    "\n",
    "# Create and compile the model\n",
    "print(\"Creating and compiling the model\")\n",
    "model = unet_model()\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=[dice_coef])\n",
    "\n",
    "# Define the model checkpoint\n",
    "checkpoint = ModelCheckpoint('unet.hdf5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model\")\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, epochs=50, callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe623a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model = unet_model()\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=[dice_coef])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n",
    "\n",
    "# Save the model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4cc00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming test_images is your array of test images and pred_masks is your array of predicted masks\n",
    "for i in range(len(test_images)):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Show original image\n",
    "    ax[0].imshow(test_images[i], cmap='gray')\n",
    "    ax[0].set_title('Original Image')\n",
    "\n",
    "    # Show mask (predicted by the model)\n",
    "    ax[1].imshow(np.squeeze(pred_masks[i]), cmap='gray')\n",
    "    ax[1].set_title('Predicted Mask')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee135a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from keras.models import load_model\n",
    "from base_ship.train_model import dice_coef\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('model.h5', custom_objects={'dice_coef': dice_coef})\n",
    "\n",
    "# Define the directory path where your data is stored\n",
    "data_dir = 'actual_path'\n",
    "\n",
    "# Load the CSV file\n",
    "df_test = pd.read_csv(os.path.join(data_dir, 'test_ship_segmentations_v2.csv'))\n",
    "\n",
    "# Initialize a list to store the images\n",
    "images_test = []\n",
    "\n",
    "# Loop over the rows of the DataFrame\n",
    "for idx, row in df_test.iterrows():\n",
    "    # Get the image ID\n",
    "    image_id = row['ImageId']\n",
    "\n",
    "    # Open the image file\n",
    "    image = Image.open(os.path.join(data_dir, f'{image_id}'))\n",
    "\n",
    "    # Append the image to the list\n",
    "    images_test.append(np.array(image))\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "X_test = np.array(images_test)\n",
    "\n",
    "# Use the model to make predictions\n",
    "predictions = model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
